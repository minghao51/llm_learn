{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.environ.get(\"GROQ\")\n",
    "GOOGLE_API_KEY = os.environ.get(\"GOOGLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'groq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m Groq(\n\u001b[1;32m      4\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mGROQ_API_KEY,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      9\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixtral-8x7b-32768\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'groq'"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of low latency LLMs\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Via Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Client\n",
    "chat = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "# Setup\n",
    "# Write a prompt and invoke ChatGroq to create completions:\n",
    "system = \"You are a helpful assistant.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | chat\n",
    "response = chain.invoke({\"text\": \"Explain the importance of low latency LLMs.\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Via Langchain + System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You're running on reserves but soon you'll get a chance to recharge!\\n\\n(I'm here to make your text more positive and engaging!)\\n\\nLet me know if you need help with that or anything else!\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Client\n",
    "chat = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "# Setup\n",
    "# Write a prompt and invoke ChatGroq to create completions:\n",
    "system = \"You are a helpful assistant that re-writes the user's text to sound more upbeat\"\n",
    "\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | chat\n",
    "response = chain.invoke({\"text\": \"I am tired\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05636945, 0.0048285457, -0.0762591, -0.023642512, 0.05329321]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key = GOOGLE_API_KEY)\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = embeddings.embed_documents(\n",
    "    [\n",
    "        \"Today is Monday\",\n",
    "        \"Today is Tuesday\",\n",
    "        \"Today is April Fools day\",\n",
    "    ]\n",
    ")\n",
    "len(vectors), len(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"# FWD Big 3: Comprehensive Protection for What Matters Most\\nDescription: In today's world, unexpected health events can have a significant financial impact. FWD's Big 3 Critical Illness insurance plan offers affordable and convenient protection against three of the most common critical illnesses: cancer, heart attack, and stroke.\\n\\n## Benefits:\\n\\n- One-time lump sum payout: Upon diagnosis of any covered critical illness, you'll receive a 100% cash payout of your chosen sum insured (up to S$200,000). This allows you to focus on your recovery without financial worry.\\n- Flexible coverage options: Choose from three coverage amounts (S$50,000, S$100,000, or S$200,000) to suit your needs and budget.\\n- No medical examination required: Get covered quickly and easily by answering a simple health declaration. This eliminates the need for a medical exam, making the application process fast and convenient.\\n- Bridge the protection gap: This plan can be used as a standalone policy or to complement your existing coverage, ensuring you have adequate financial protection in case of a critical illness.\\n- Affordable premiums: FWD's Big 3 is known for its competitive pricing, making it an accessible option for many individuals.\\n\\nCost: The cost of your FWD Big 3 policy will vary depending on several factors, including your age, health status, and chosen coverage amount. However, FWD is known for offering competitive rates, making critical illness protection more affordable than ever.\\n\\nHere's an example: A 35-year-old non-smoking male can get S$50,000 of coverage for as low as S$18 per month.\\n\\nInvest in peace of mind with FWD's Big 3 Critical Illness insurance. Contact us today for a free quote and learn how this plan can protect you and your loved ones.\", metadata={'source': 'assets/fwd_big3.md'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"assets/fwd_big3.md\").load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma\n",
    "incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save to disk\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Data\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgemini_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Embedding model\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m#  persist_directory=\"./chroma_db\" # Directory to save data\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create a retriever using Chroma\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load from disk\u001b[39;00m\n\u001b[1;32m     14\u001b[0m vectorstore_disk \u001b[38;5;241m=\u001b[39m Chroma(\n\u001b[1;32m     15\u001b[0m                     \u001b[38;5;66;03m#     persist_directory=\"./chroma_db\",       # Directory of db\u001b[39;00m\n\u001b[1;32m     16\u001b[0m                         embedding_function\u001b[38;5;241m=\u001b[39mgemini_embeddings   \u001b[38;5;66;03m# Embedding model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m                    )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:778\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    777\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:714\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    694\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[1;32m    695\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \n\u001b[1;32m    697\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m     chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m         ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid1()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:81\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with a Chroma client.\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/__init__.py:79\u001b[0m\n\u001b[1;32m     77\u001b[0m             sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpysqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     80\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91mYour system has an unsupported version of sqlite3. Chroma \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124m                    requires sqlite3 >= 3.35.0.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[94mPlease visit \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124m                    https://docs.trychroma.com/troubleshooting#sqlite to learn how \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124m                    to upgrade.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m             )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override Chroma's default settings, environment variables or .env files\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key = GOOGLE_API_KEY)\n",
    "\n",
    "docs = loader\n",
    "# Save to disk\n",
    "vectorstore = Chroma.from_documents(\n",
    "                     documents=docs,                 # Data\n",
    "                     embedding=gemini_embeddings,    # Embedding model\n",
    "                    #  persist_directory=\"./chroma_db\" # Directory to save data\n",
    "                     )\n",
    "# Create a retriever using Chroma\n",
    "# Load from disk\n",
    "vectorstore_disk = Chroma(\n",
    "                    #     persist_directory=\"./chroma_db\",       # Directory of db\n",
    "                        embedding_function=gemini_embeddings   # Embedding model\n",
    "                   )\n",
    "# 1. If you don't pass this value, you will get a warning.\n",
    "retriever = vectorstore_disk.as_retriever( search_kwargs={\"k\": 15}) #\" \"score_threshold\": .3 search_type ='similarity_score_threshold',\n",
    "\n",
    "# Check if the retriever is working by trying to fetch the relevant docs related\n",
    "# to the word 'climate'. If the length is greater than zero, it means that\n",
    "# the retriever is functioning well.\n",
    "print(len(retriever.get_relevant_documents(\"claims for critical illness\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain + Documents Loader + RAG\n",
    "incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# from langchain_openai.chat_models import ChatOpenAI\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m      8\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m DocArrayInMemorySearch\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[1;32m      9\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mharrison worked at kensho\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbears like to eat honey\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m---> 10\u001b[0m     embedding\u001b[38;5;241m=\u001b[39m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m     14\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mAnswer the question based only on the following context:\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;132;01m{context}\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "\n",
    "# from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "# # from langchain_openai.chat_models import ChatOpenAI\n",
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "#     [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "#     embedding=OpenAIEmbeddings(),\n",
    "# )\n",
    "# retriever = vectorstore.as_retriever()\n",
    "\n",
    "# template = \"\"\"Answer the question based only on the following context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "# model = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=\"mixtral-8x7b-32768\")\n",
    "# output_parser = StrOutputParser()\n",
    "\n",
    "# setup_and_retrieval = RunnableParallel(\n",
    "#     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "# )\n",
    "# chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "# chain.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = JSONLoader(\n",
    "#     file_path='assets/dune_characters.json',\n",
    "#     jq_schema='',\n",
    "#     text_content=False)\n",
    "\n",
    "# data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='assets/dune_characters.json'\n",
    "data = json.loads(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Paul Atreides',\n",
       "  'description': 'The young protagonist and heir of House Atreides. He is trained in combat, strategy, and possesses unique mental abilities. Paul is a complex and conflicted character, wrestling with his destiny and the potential for both heroism and tyranny.',\n",
       "  'character': 'Hero, Messiah',\n",
       "  'persona': 'Reserved, contemplative, burdened by responsibility'},\n",
       " {'name': 'Lady Jessica',\n",
       "  'description': \"Paul's mother, a member of the Bene Gesserit sisterhood with advanced mental and physical training. Lady Jessica is a strong and intelligent woman, torn between her loyalty to her son and the Bene Gesserit.\",\n",
       "  'character': 'Bene Gesserit Reverend Mother, mother',\n",
       "  'persona': 'Stoic, cunning, protective'},\n",
       " {'name': 'Duke Leto Atreides',\n",
       "  'description': \"Paul's father, a noble and just leader of House Atreides entrusted with governing Arrakis. Duke Leto is a wise and compassionate leader, respected for his fairness and integrity.\",\n",
       "  'character': 'Noble Duke, father',\n",
       "  'persona': 'Diplomatic, courageous, honorable'},\n",
       " {'name': 'Baron Vladimir Harkonnen',\n",
       "  'description': 'The ruthless and cruel leader of House Harkonnen, the sworn enemies of House Atreides. The Baron is a sadistic and power-hungry individual, willing to use any means necessary to achieve his goals.',\n",
       "  'character': 'Ruthless villain, leader of House Harkonnen',\n",
       "  'persona': 'Cruel, manipulative, power-hungry'},\n",
       " {'name': 'Chani',\n",
       "  'description': \"A young Fremen woman who becomes important to Paul's journey and understanding of Arrakis. Chani is a skilled survivalist and fierce protector of her people, with a deep connection to the desert.\",\n",
       "  'character': 'Fremen woman, love interest',\n",
       "  'persona': 'Fierce, independent, connected to nature'},\n",
       " {'name': 'Stilgar',\n",
       "  'description': 'The leader of a Fremen tribe who takes Paul and Jessica in after they flee into the desert. Stilgar is a wise and experienced leader, deeply respectful of Fremen traditions.',\n",
       "  'character': 'Fremen leader, mentor',\n",
       "  'persona': 'Stoic, wise, respectful of tradition'},\n",
       " {'name': 'Duncan Idaho',\n",
       "  'description': 'A loyal swordsman and close friend to the Atreides family, skilled in combat and tactics. Duncan is a brave and honorable warrior, willing to fight to the death for those he cares about.',\n",
       "  'character': 'Loyal warrior, friend',\n",
       "  'persona': 'Courageous, skilled, unwavering in loyalty'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'markdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m markdown_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massets/fwd_big3.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mUnstructuredMarkdownLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkdown_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:29\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/document_loaders/unstructured.py:87\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_elements(elements)\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/document_loaders/markdown.py:32\u001b[0m, in \u001b[0;36mUnstructuredMarkdownLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__version__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m __unstructured_version__\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition_md\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# NOTE(MthwRobinson) - enables the loader to work when you're using pre-release\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# versions of unstructured like 0.4.17-dev1\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     _unstructured_version \u001b[38;5;241m=\u001b[39m __unstructured_version__\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured/partition/md.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IO, List, Optional, Union\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmarkdown\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_chunking_strategy\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'markdown'"
     ]
    }
   ],
   "source": [
    "markdown_path = \"assets/fwd_big3.md\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path).load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
